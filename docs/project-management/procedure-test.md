# Procédure de test standardisée - Studio d'Impact Local

Ce document établit une méthodologie commune pour tester et valider tous les livrables du Studio d'Impact Local, garantissant une qualité constante et une amélioration continue.

## 1. Types de livrables et critères de qualité

### Livrables de type "Canvas"
- **Critères esthétiques** : Lisibilité, harmonie visuelle, cohérence avec l'identité du Studio
- **Critères fonctionnels** : Facilité d'utilisation, compréhension intuitive, efficacité du processus
- **Critères pédagogiques** : Clarté des instructions, progressivité de l'apprentissage

### Livrables de type "Narration"
- **Critères narratifs** : Cohérence du récit, impact émotionnel, mémorabilité
- **Critères structurels** : Respect de la structure en 5 étapes, fluidité des transitions
- **Critères communicationnels** : Clarté du message, adaptation à l'audience, efficacité persuasive

### Livrables de type "Micro-centre"
- **Critères spatiaux** : Ergonomie, modularité, optimisation de l'espace
- **Critères économiques** : Viabilité financière, optimisation des ressources
- **Critères d'impact** : Potentiel transformatif, mesurabilité des effets

### Livrables transversaux (documentation, outils, etc.)
- **Critères techniques** : Fonctionnalité, fiabilité, facilité d'utilisation
- **Critères didactiques** : Clarté, complétude, adaptabilité aux différents niveaux
- **Critères de reproductibilité** : Documentation claire, accessibilité, scalabilité

## 2. Processus de test en 4 phases

### Phase 1: Test interne (équipe du Studio)
1. **Auto-évaluation** par le créateur du livrable selon les critères définis
2. **Revue par les pairs** (au moins 2 membres de l'équipe)
3. **Itération** sur la base des retours internes

### Phase 2: Test avec utilisateurs "amis" (cercle proche)
1. **Sélection** de 3-5 testeurs proches mais non impliqués dans la création
2. **Session guidée** avec observation directe
3. **Recueil de feedback** via questionnaire standardisé et entretien
4. **Ajustements** selon les retours obtenus

### Phase 3: Test avec groupe cible restreint
1. **Sélection** de 5-8 représentants du public cible
2. **Test en conditions réelles** (minimalement supervisé)
3. **Collecte mixte** de données quantitatives et qualitatives
4. **Analyse** des points forts et des obstacles rencontrés
5. **Améliorations** basées sur l'analyse

### Phase 4: Déploiement contrôlé et amélioration continue
1. **Lancement limité** auprès d'un groupe de pionniers (10-15 personnes)
2. **Suivi régulier** et support proactif
3. **Recueil systématique** de feedback (automatisé + entretiens)
4. **Itérations régulières** et documentation des apprentissages

## 3. Outils de collecte de feedback

### Questionnaires standardisés
- **Questionnaire pré-test** (attentes, niveau de compétence, contexte)
- **Questionnaire post-test immédiat** (expérience d'utilisation, difficultés, satisfactions)
- **Questionnaire différé** (2-4 semaines après, utilité réelle, intégration dans les pratiques)

### Grilles d'observation
- **Comportements observables** (hésitations, erreurs, expressions de satisfaction)
- **Points de friction** (là où les utilisateurs bloquent ou ralentissent)
- **Parcours d'utilisation** (cheminement réel vs cheminement anticipé)

### Entretiens semi-directifs
- **Guide d'entretien standardisé** adapté à chaque type de livrable
- **Questions ouvertes** centrées sur l'expérience globale
- **Exploration des améliorations** souhaitées par l'utilisateur

## 4. Analyse et traitement des résultats

### Processus de priorisation
1. **Catégorisation** des retours (bugs, améliorations mineures, évolutions majeures)
2. **Matrice impact/effort** pour prioriser les actions
3. **Validation collégiale** des priorités identifiées

### Documentation des apprentissages
1. **Rapport de synthèse** après chaque phase de test
2. **Documentation des modifications** apportées et leur justification
3. **Alimentation d'une base de connaissances** centralisée

### Suivi longitudinal
1. **Tableau de bord** d'évolution de la satisfaction utilisateurs
2. **Indicateurs clés** spécifiques à chaque type de livrable
3. **Revue trimestrielle** de l'efficacité du processus de test lui-même

## 5. Modèles et templates

### Template de rapport de test
```markdown
# Rapport de test: [Nom du livrable]

## Informations générales
- **Date du test**: [Date]
- **Version testée**: [Version]
- **Nombre de testeurs**: [Nombre]
- **Profil des testeurs**: [Description]

## Résultats quantitatifs
- **Score de satisfaction globale**: [Score/10]
- **Taux de complétion des tâches**: [%]
- **Temps moyen d'utilisation**: [Durée]

## Points forts identifiés
1. [Point fort 1]
2. [Point fort 2]
3. [Point fort 3]

## Points d'amélioration
1. [Point d'amélioration 1] - Priorité: [Haute/Moyenne/Basse]
2. [Point d'amélioration 2] - Priorité: [Haute/Moyenne/Basse]
3. [Point d'amélioration 3] - Priorité: [Haute/Moyenne/Basse]

## Plan d'action
- **Actions immédiates**: [Liste d'actions]
- **Évolutions à moyen terme**: [Liste d'évolutions]
- **Questions ouvertes**: [Liste de questions]

## Annexes
- [Lien vers les données brutes]
- [Lien vers les enregistrements]
```

### Formulaire de feedback utilisateur (exemple)
```markdown
# Votre expérience avec [Nom du livrable]

## À propos de vous
- Comment décririez-vous votre projet/activité? [Champ libre]
- Quel est votre niveau d'expérience dans ce domaine? [Débutant/Intermédiaire/Avancé]

## Votre utilisation
- Avez-vous pu accomplir l'objectif visé? [Oui/Partiellement/Non]
- Combien de temps avez-vous passé à utiliser l'outil? [Durée]
- Quelles parties vous ont semblé les plus utiles? [Champ libre]
- Où avez-vous rencontré des difficultés? [Champ libre]

## Votre évaluation
- Sur une échelle de 1 à 10, quelle est votre satisfaction globale? [Échelle]
- Dans quelle mesure cet outil répond-il à vos besoins? [Échelle]
- Recommanderiez-vous cet outil à d'autres? [Oui/Peut-être/Non]

## Vos suggestions
- Quelles améliorations suggéreriez-vous? [Champ libre]
- Quelles fonctionnalités aimeriez-vous voir ajoutées? [Champ libre]
- Avez-vous d'autres commentaires? [Champ libre]
```

## 6. Mise en œuvre et responsabilités

### Rôles clés
- **Coordinateur de tests**: Supervise l'ensemble du processus de test
- **Gestionnaire de feedback**: Centralise et organise les retours utilisateurs
- **Responsables de livrable**: Implémentent les ajustements nécessaires

### Calendrier recommandé
- **Tests internes**: 2-3 jours selon la complexité du livrable
- **Tests avec utilisateurs proches**: 1 semaine
- **Tests avec groupe cible**: 2-3 semaines
- **Analyse et itération**: 1-2 semaines

### Intégration dans le flux de travail global
- Planification des phases de test dans les sprints de développement
- Création d'issues GitHub spécifiques pour les améliorations identifiées
- Documentation des décisions de non-implémentation (avec justification)

---

Cette procédure de test est un document évolutif qui sera lui-même soumis à évaluation et amélioration régulière en fonction des retours d'expérience de l'équipe.